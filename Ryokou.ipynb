{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/17/t_n64d8d39s99ps2q3b67hmr0000gn/T/ipykernel_9346/952689514.py:53: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  onsen_element = detail_soup.find('th', text='温泉')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "スクレイピングしたホテル情報を 'hotels.db' に保存し、'hotels_data.csv' に書き出しました。\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (1) データベースの初期設定: DBファイルとテーブル準備\n",
    "# ----------------------------------------------------\n",
    "db_name = 'hotels.db'\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# 既存のテーブルを削除して再作成\n",
    "cursor.execute('DROP TABLE IF EXISTS hotels')\n",
    "\n",
    "# 新しいテーブルを作成\n",
    "cursor.execute('''\n",
    "    CREATE TABLE hotels (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        name TEXT,\n",
    "        detail_url TEXT,\n",
    "        onsen_info TEXT\n",
    "    )\n",
    "''')\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (2) ランキングサイトのURLを設定してスクレイピング\n",
    "# ----------------------------------------------------\n",
    "ranking_url = 'https://www.jalan.net/jalan/doc/kokyuyado-ranking/?ctm=N11'\n",
    "response = requests.get(ranking_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# ホテル名と詳細ページを取得\n",
    "hotel_links = []\n",
    "for a_tag in soup.find_all('a', href=True):\n",
    "    href = a_tag['href']\n",
    "    text = a_tag.get_text(strip=True)\n",
    "    if 'uww3001.do' in href and text:\n",
    "        full_url = 'https://www.jalan.net' + href\n",
    "        hotel_links.append((text, full_url))\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (3) 各ホテルページから温泉情報を取得しDBに格納\n",
    "# ----------------------------------------------------\n",
    "for hotel_name, detail_url in hotel_links:\n",
    "    time.sleep(2)  # サーバ負荷を軽減するために2秒の遅延を追加\n",
    "    detail_response = requests.get(detail_url)\n",
    "    detail_soup = BeautifulSoup(detail_response.content, 'html.parser')\n",
    "    \n",
    "    # 温泉情報を検索\n",
    "    onsen_element = detail_soup.find('th', text='温泉')\n",
    "    if onsen_element:\n",
    "        onsen_info = onsen_element.find_next_sibling('td')\n",
    "        if onsen_info:\n",
    "            onsen_text = onsen_info.get_text(strip=True)\n",
    "        else:\n",
    "            onsen_text = '不明'\n",
    "    else:\n",
    "        onsen_text = '不明'\n",
    "    \n",
    "    # データベースに保存\n",
    "    cursor.execute('''\n",
    "        INSERT INTO hotels (name, detail_url, onsen_info)\n",
    "        VALUES (?, ?, ?)\n",
    "    ''', (hotel_name, detail_url, onsen_text))\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (4) DBからデータを読み込んでCSVファイルに出力\n",
    "# ----------------------------------------------------\n",
    "# CSVファイル名\n",
    "csv_file = 'hotels_data.csv'\n",
    "\n",
    "# 既存のCSVファイルがあれば削除（必要に応じて処理を変更）\n",
    "if os.path.exists(csv_file):\n",
    "    os.remove(csv_file)\n",
    "\n",
    "# DBからデータ取得\n",
    "cursor.execute('SELECT name, detail_url, onsen_info FROM hotels')\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# CSVに書き込み\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # ヘッダー\n",
    "    writer.writerow(['Hotel Name', 'Detail URL', 'Onsen Info'])\n",
    "    # データ\n",
    "    writer.writerows(rows)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(f\"スクレイピングしたホテル情報を '{db_name}' に保存し、'{csv_file}' に書き出しました。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/17/t_n64d8d39s99ps2q3b67hmr0000gn/T/ipykernel_9346/2055128154.py:53: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  onsen_element = detail_soup.find('th', text='温泉')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "スクレイピングしたホテル情報を 'hotels_onsen_info.db' に保存し、'hotels_onsen_info.csv' に書き出しました。\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (1) データベースの初期設定: DBファイルとテーブル準備\n",
    "# ----------------------------------------------------\n",
    "db_name = 'hotels_onsen_info.db'\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# 既存のテーブルを削除して再作成\n",
    "cursor.execute('DROP TABLE IF EXISTS hotels')\n",
    "\n",
    "# 新しいテーブルを作成\n",
    "cursor.execute('''\n",
    "    CREATE TABLE hotels (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        name TEXT,\n",
    "        detail_url TEXT,\n",
    "        onsen_info TEXT\n",
    "    )\n",
    "''')\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (2) ランキングサイトのURLを設定してスクレイピング\n",
    "# ----------------------------------------------------\n",
    "ranking_url = 'https://www.jalan.net/jalan/doc/kokyuyado-ranking/room-dinner00.html'\n",
    "response = requests.get(ranking_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# ホテル名と詳細ページを取得\n",
    "hotel_links = []\n",
    "for a_tag in soup.find_all('a', href=True):\n",
    "    href = a_tag['href']\n",
    "    text = a_tag.get_text(strip=True)\n",
    "    if 'uww3001.do' in href and text:\n",
    "        full_url = 'https://www.jalan.net' + href\n",
    "        hotel_links.append((text, full_url))\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (3) 各ホテルページから温泉情報を取得しDBに格納\n",
    "# ----------------------------------------------------\n",
    "for hotel_name, detail_url in hotel_links:\n",
    "    time.sleep(2)  # サーバ負荷を軽減するために2秒の遅延を追加\n",
    "    detail_response = requests.get(detail_url)\n",
    "    detail_soup = BeautifulSoup(detail_response.content, 'html.parser')\n",
    "    \n",
    "    # 温泉情報を検索\n",
    "    onsen_element = detail_soup.find('th', text='温泉')\n",
    "    if onsen_element:\n",
    "        onsen_info = onsen_element.find_next_sibling('td')\n",
    "        if onsen_info:\n",
    "            onsen_text = onsen_info.get_text(strip=True)\n",
    "        else:\n",
    "            onsen_text = '不明'\n",
    "    else:\n",
    "        onsen_text = '不明'\n",
    "    \n",
    "    # データベースに保存\n",
    "    cursor.execute('''\n",
    "        INSERT INTO hotels (name, detail_url, onsen_info)\n",
    "        VALUES (?, ?, ?)\n",
    "    ''', (hotel_name, detail_url, onsen_text))\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (4) DBからデータを読み込んでCSVファイルに出力\n",
    "# ----------------------------------------------------\n",
    "# CSVファイル名\n",
    "csv_file = 'hotels_onsen_info.csv'\n",
    "\n",
    "# 既存のCSVファイルがあれば削除（必要に応じて処理を変更）\n",
    "if os.path.exists(csv_file):\n",
    "    os.remove(csv_file)\n",
    "\n",
    "# DBからデータ取得\n",
    "cursor.execute('SELECT name, detail_url, onsen_info FROM hotels')\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# CSVに書き込み\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8-sig') as f:\n",
    "    writer = csv.writer(f, quoting=csv.QUOTE_NONNUMERIC)\n",
    "    # ヘッダー\n",
    "    writer.writerow(['Hotel Name', 'Detail URL', 'Onsen Info'])\n",
    "    # データ\n",
    "    writer.writerows(rows)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(f\"スクレイピングしたホテル情報を '{db_name}' に保存し、'{csv_file}' に書き出しました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/17/t_n64d8d39s99ps2q3b67hmr0000gn/T/ipykernel_9346/2646136354.py:55: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  onsen_element = detail_soup.find('th', text='温泉')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "スクレイピングしたホテル情報を 'hotels_onsen_info.db' に保存し、'hotels_onsen_info2.csv' に書き出しました。\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (1) データベースの初期設定: DBファイルとテーブル準備\n",
    "# ----------------------------------------------------\n",
    "db_name = 'hotels_onsen_info.db'\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# 既存のテーブルを削除して再作成\n",
    "cursor.execute('DROP TABLE IF EXISTS hotels')\n",
    "\n",
    "# 新しいテーブルを作成\n",
    "cursor.execute('''\n",
    "    CREATE TABLE hotels (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        name TEXT,\n",
    "        detail_url TEXT,\n",
    "        onsen_info TEXT\n",
    "    )\n",
    "''')\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (2) ランキングサイトのURLを設定してスクレイピング\n",
    "# ----------------------------------------------------\n",
    "ranking_url = 'https://www.jalan.net/jalan/doc/kokyuyado-ranking/room-nodinner00.html'\n",
    "response = requests.get(ranking_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# ホテル名と詳細ページを取得\n",
    "hotel_links = []\n",
    "for a_tag in soup.find_all('a', href=True):\n",
    "    href = a_tag['href']\n",
    "    text = a_tag.get_text(strip=True)\n",
    "    if 'uww3001.do' in href and text:\n",
    "        full_url = 'https://www.jalan.net' + href\n",
    "        hotel_links.append((text, full_url))\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (3) 各ホテルページから温泉情報を取得しDBに格納\n",
    "# ----------------------------------------------------\n",
    "for hotel_name, detail_url in hotel_links:\n",
    "    time.sleep(2)  # サーバ負荷を軽減するために2秒の遅延を追加\n",
    "    detail_response = requests.get(detail_url)\n",
    "    detail_soup = BeautifulSoup(detail_response.content, 'html.parser')\n",
    "    \n",
    "    # 温泉情報を検索\n",
    "    onsen_element = detail_soup.find('th', text='温泉')\n",
    "    if onsen_element:\n",
    "        onsen_info = onsen_element.find_next_sibling('td')\n",
    "        if onsen_info:\n",
    "            onsen_text = onsen_info.get_text(strip=True)\n",
    "        else:\n",
    "            onsen_text = '不明'\n",
    "    else:\n",
    "        onsen_text = '不明'\n",
    "    \n",
    "    # データベースに保存\n",
    "    cursor.execute('''\n",
    "        INSERT INTO hotels (name, detail_url, onsen_info)\n",
    "        VALUES (?, ?, ?)\n",
    "    ''', (hotel_name, detail_url, onsen_text))\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (4) DBからデータを読み込んでCSVファイルに出力\n",
    "# ----------------------------------------------------\n",
    "# CSVファイル名\n",
    "csv_file = 'hotels_onsen_info2.csv'\n",
    "\n",
    "# 既存のCSVファイルがあれば削除（必要に応じて処理を変更）\n",
    "if os.path.exists(csv_file):\n",
    "    os.remove(csv_file)\n",
    "\n",
    "# DBからデータ取得\n",
    "cursor.execute('SELECT name, detail_url, onsen_info FROM hotels')\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# CSVに書き込み\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # ヘッダー\n",
    "    writer.writerow(['Hotel Name', 'Detail URL', 'Onsen Info'])\n",
    "    # データ\n",
    "    writer.writerows(rows)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(f\"スクレイピングしたホテル情報を '{db_name}' に保存し、'{csv_file}' に書き出しました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/17/t_n64d8d39s99ps2q3b67hmr0000gn/T/ipykernel_9346/3462684233.py:51: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  onsen_element = detail_soup.find('th', text='温泉')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "スクレイピングしたホテル情報を 'hotels_onsen_info_hitori.db' に保存し、'hotels_onsen_info_hitori3.csv' に書き出しました。\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (1) データベースの初期設定: DBファイルとテーブル準備\n",
    "# ----------------------------------------------------\n",
    "db_name = 'hotels_onsen_info_hitori.db'\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# 既存のテーブルを削除して再作成\n",
    "cursor.execute('DROP TABLE IF EXISTS hotels')\n",
    "\n",
    "# 新しいテーブルを作成\n",
    "cursor.execute('''\n",
    "    CREATE TABLE hotels (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        name TEXT,\n",
    "        detail_url TEXT,\n",
    "        onsen_info TEXT\n",
    "    )\n",
    "''')\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (2) ランキングサイトのURLを設定してスクレイピング\n",
    "# ----------------------------------------------------\n",
    "ranking_url = 'https://www.jalan.net/jalan/doc/kokyuyado-ranking/room-hitori00.html'\n",
    "response = requests.get(ranking_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# ホテル名と詳細ページを取得\n",
    "hotel_links = []\n",
    "for a_tag in soup.find_all('a', href=True):\n",
    "    href = a_tag['href']\n",
    "    text = a_tag.get_text(strip=True)\n",
    "    if 'uww3001.do' in href and text:\n",
    "        full_url = 'https://www.jalan.net' + href\n",
    "        hotel_links.append((text, full_url))\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (3) 各ホテルページから温泉情報を取得しDBに格納\n",
    "# ----------------------------------------------------\n",
    "for hotel_name, detail_url in hotel_links:\n",
    "    time.sleep(2)  # サーバ負荷を軽減するために2秒の遅延を追加\n",
    "    detail_response = requests.get(detail_url)\n",
    "    detail_soup = BeautifulSoup(detail_response.content, 'html.parser')\n",
    "    \n",
    "    # 温泉情報を検索\n",
    "    onsen_element = detail_soup.find('th', text='温泉')\n",
    "    if onsen_element:\n",
    "        onsen_info = onsen_element.find_next_sibling('td')\n",
    "        if onsen_info:\n",
    "            onsen_text = onsen_info.get_text(strip=True)\n",
    "        else:\n",
    "            onsen_text = '不明'\n",
    "    else:\n",
    "        onsen_text = '不明'\n",
    "    \n",
    "    # データベースに保存\n",
    "    cursor.execute('''\n",
    "        INSERT INTO hotels (name, detail_url, onsen_info)\n",
    "        VALUES (?, ?, ?)\n",
    "    ''', (hotel_name, detail_url, onsen_text))\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (4) DBからデータを読み込んでCSVファイルに出力\n",
    "# ----------------------------------------------------\n",
    "# CSVファイル名\n",
    "csv_file = 'hotels_onsen_info_hitori3.csv'\n",
    "\n",
    "# 既存のCSVファイルがあれば削除（必要に応じて処理を変更）\n",
    "if os.path.exists(csv_file):\n",
    "    os.remove(csv_file)\n",
    "\n",
    "# DBからデータ取得\n",
    "cursor.execute('SELECT name, detail_url, onsen_info FROM hotels')\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# CSVに書き込み\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # ヘッダー\n",
    "    writer.writerow(['Hotel Name', 'Detail URL', 'Onsen Info'])\n",
    "    # データ\n",
    "    writer.writerows(rows)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(f\"スクレイピングしたホテル情報を '{db_name}' に保存し、'{csv_file}' に書き出しました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/17/t_n64d8d39s99ps2q3b67hmr0000gn/T/ipykernel_8278/1274366309.py:51: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  onsen_element = detail_soup.find('th', text='温泉')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "スクレイピングしたホテル情報を 'hotels_onsen_info_dinner.db' に保存し、'hotels_onsen_info_dinner４.csv' に書き出しました。\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (1) データベースの初期設定: DBファイルとテーブル準備\n",
    "# ----------------------------------------------------\n",
    "db_name = 'hotels_onsen_info_dinner.db'\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# 既存のテーブルを削除して再作成\n",
    "cursor.execute('DROP TABLE IF EXISTS hotels')\n",
    "\n",
    "# 新しいテーブルを作成\n",
    "cursor.execute('''\n",
    "    CREATE TABLE hotels (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        name TEXT,\n",
    "        detail_url TEXT,\n",
    "        onsen_info TEXT\n",
    "    )\n",
    "''')\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (2) ランキングサイトのURLを設定してスクレイピング\n",
    "# ----------------------------------------------------\n",
    "ranking_url = 'https://www.jalan.net/jalan/doc/kokyuyado-ranking/plan-dinner00.html'\n",
    "response = requests.get(ranking_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# ホテル名と詳細ページを取得\n",
    "hotel_links = []\n",
    "for a_tag in soup.find_all('a', href=True):\n",
    "    href = a_tag['href']\n",
    "    text = a_tag.get_text(strip=True)\n",
    "    if 'uww3001.do' in href and text:\n",
    "        full_url = 'https://www.jalan.net' + href\n",
    "        hotel_links.append((text, full_url))\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (3) 各ホテルページから温泉情報を取得しDBに格納\n",
    "# ----------------------------------------------------\n",
    "for hotel_name, detail_url in hotel_links:\n",
    "    time.sleep(2)  # サーバ負荷を軽減するために2秒の遅延を追加\n",
    "    detail_response = requests.get(detail_url)\n",
    "    detail_soup = BeautifulSoup(detail_response.content, 'html.parser')\n",
    "    \n",
    "    # 温泉情報を検索\n",
    "    onsen_element = detail_soup.find('th', text='温泉')\n",
    "    if onsen_element:\n",
    "        onsen_info = onsen_element.find_next_sibling('td')\n",
    "        if onsen_info:\n",
    "            onsen_text = onsen_info.get_text(strip=True)\n",
    "        else:\n",
    "            onsen_text = '不明'\n",
    "    else:\n",
    "        onsen_text = '不明'\n",
    "    \n",
    "    # データベースに保存\n",
    "    cursor.execute('''\n",
    "        INSERT INTO hotels (name, detail_url, onsen_info)\n",
    "        VALUES (?, ?, ?)\n",
    "    ''', (hotel_name, detail_url, onsen_text))\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (4) DBからデータを読み込んでCSVファイルに出力\n",
    "# ----------------------------------------------------\n",
    "# CSVファイル名\n",
    "csv_file = 'hotels_onsen_info_dinner４.csv'\n",
    "\n",
    "# 既存のCSVファイルがあれば削除（必要に応じて処理を変更）\n",
    "if os.path.exists(csv_file):\n",
    "    os.remove(csv_file)\n",
    "\n",
    "# DBからデータ取得\n",
    "cursor.execute('SELECT name, detail_url, onsen_info FROM hotels')\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# CSVに書き込み\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # ヘッダー\n",
    "    writer.writerow(['Hotel Name', 'Detail URL', 'Onsen Info'])\n",
    "    # データ\n",
    "    writer.writerows(rows)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(f\"スクレイピングしたホテル情報を '{db_name}' に保存し、'{csv_file}' に書き出しました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (1) データベースの初期設定: DBファイルとテーブル準備\n",
    "# ----------------------------------------------------\n",
    "db_name = 'hotels_onsen_info_nodinner.db'\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# 既存のテーブルを削除して再作成\n",
    "cursor.execute('DROP TABLE IF EXISTS hotels')\n",
    "\n",
    "# 新しいテーブルを作成\n",
    "cursor.execute('''\n",
    "    CREATE TABLE hotels (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        name TEXT,\n",
    "        detail_url TEXT,\n",
    "        onsen_info TEXT\n",
    "    )\n",
    "''')\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (2) ランキングサイトのURLを設定してスクレイピング\n",
    "# ----------------------------------------------------\n",
    "ranking_url = 'https://www.jalan.net/jalan/doc/kokyuyado-ranking/plan-nodinner00.html'\n",
    "response = requests.get(ranking_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# ホテル名と詳細ページを取得\n",
    "hotel_links = []\n",
    "for a_tag in soup.find_all('a', href=True):\n",
    "    href = a_tag['href']\n",
    "    text = a_tag.get_text(strip=True)\n",
    "    if 'uww3001.do' in href and text:\n",
    "        full_url = 'https://www.jalan.net' + href\n",
    "        hotel_links.append((text, full_url))\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (3) 各ホテルページから温泉情報を取得しDBに格納\n",
    "# ----------------------------------------------------\n",
    "for hotel_name, detail_url in hotel_links:\n",
    "    time.sleep(2)  # サーバ負荷を軽減するために2秒の遅延を追加\n",
    "    detail_response = requests.get(detail_url)\n",
    "    detail_soup = BeautifulSoup(detail_response.content, 'html.parser')\n",
    "    \n",
    "    # 温泉情報を検索\n",
    "    onsen_element = detail_soup.find('th', text='温泉')\n",
    "    if onsen_element:\n",
    "        onsen_info = onsen_element.find_next_sibling('td')\n",
    "        if onsen_info:\n",
    "            onsen_text = onsen_info.get_text(strip=True)\n",
    "        else:\n",
    "            onsen_text = '不明'\n",
    "    else:\n",
    "        onsen_text = '不明'\n",
    "    \n",
    "    # データベースに保存\n",
    "    cursor.execute('''\n",
    "        INSERT INTO hotels (name, detail_url, onsen_info)\n",
    "        VALUES (?, ?, ?)\n",
    "    ''', (hotel_name, detail_url, onsen_text))\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (4) DBからデータを読み込んでCSVファイルに出力\n",
    "# ----------------------------------------------------\n",
    "# CSVファイル名\n",
    "csv_file = 'hotels_onsen_info_nodinner.csv'\n",
    "\n",
    "# 既存のCSVファイルがあれば削除（必要に応じて処理を変更）\n",
    "if os.path.exists(csv_file):\n",
    "    os.remove(csv_file)\n",
    "\n",
    "# DBからデータ取得\n",
    "cursor.execute('SELECT name, detail_url, onsen_info FROM hotels')\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# CSVに書き込み\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # ヘッダー\n",
    "    writer.writerow(['Hotel Name', 'Detail URL', 'Onsen Info'])\n",
    "    # データ\n",
    "    writer.writerows(rows)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(f\"スクレイピングしたホテル情報を '{db_name}' に保存し、'{csv_file}' に書き出しました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/17/t_n64d8d39s99ps2q3b67hmr0000gn/T/ipykernel_8278/732816481.py:51: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  onsen_element = detail_soup.find('th', text='温泉')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "スクレイピングしたホテル情報を 'hotels_onsen_info_nodinner.db' に保存し、'hotels_onsen_info_nodinner5.csv' に書き出しました。\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (1) データベースの初期設定: DBファイルとテーブル準備\n",
    "# ----------------------------------------------------\n",
    "db_name = 'hotels_onsen_info_nodinner.db'\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# 既存のテーブルを削除して再作成\n",
    "cursor.execute('DROP TABLE IF EXISTS hotels')\n",
    "\n",
    "# 新しいテーブルを作成\n",
    "cursor.execute('''\n",
    "    CREATE TABLE hotels (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        name TEXT,\n",
    "        detail_url TEXT,\n",
    "        onsen_info TEXT\n",
    "    )\n",
    "''')\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (2) ランキングサイトのURLを設定してスクレイピング\n",
    "# ----------------------------------------------------\n",
    "ranking_url = 'https://www.jalan.net/jalan/doc/kokyuyado-ranking/plan-nodinner00.html'\n",
    "response = requests.get(ranking_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# ホテル名と詳細ページを取得\n",
    "hotel_links = []\n",
    "for a_tag in soup.find_all('a', href=True):\n",
    "    href = a_tag['href']\n",
    "    text = a_tag.get_text(strip=True)\n",
    "    if 'uww3001.do' in href and text:\n",
    "        full_url = 'https://www.jalan.net' + href\n",
    "        hotel_links.append((text, full_url))\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (3) 各ホテルページから温泉情報を取得しDBに格納\n",
    "# ----------------------------------------------------\n",
    "for hotel_name, detail_url in hotel_links:\n",
    "    time.sleep(2)  # サーバ負荷を軽減するために2秒の遅延を追加\n",
    "    detail_response = requests.get(detail_url)\n",
    "    detail_soup = BeautifulSoup(detail_response.content, 'html.parser')\n",
    "    \n",
    "    # 温泉情報を検索\n",
    "    onsen_element = detail_soup.find('th', text='温泉')\n",
    "    if onsen_element:\n",
    "        onsen_info = onsen_element.find_next_sibling('td')\n",
    "        if onsen_info:\n",
    "            onsen_text = onsen_info.get_text(strip=True)\n",
    "        else:\n",
    "            onsen_text = '不明'\n",
    "    else:\n",
    "        onsen_text = '不明'\n",
    "    \n",
    "    # データベースに保存\n",
    "    cursor.execute('''\n",
    "        INSERT INTO hotels (name, detail_url, onsen_info)\n",
    "        VALUES (?, ?, ?)\n",
    "    ''', (hotel_name, detail_url, onsen_text))\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# (4) DBからデータを読み込んでCSVファイルに出力\n",
    "# ----------------------------------------------------\n",
    "# CSVファイル名\n",
    "csv_file = 'hotels_onsen_info_nodinner5.csv'\n",
    "\n",
    "# 既存のCSVファイルがあれば削除（必要に応じて処理を変更）\n",
    "if os.path.exists(csv_file):\n",
    "    os.remove(csv_file)\n",
    "\n",
    "# DBからデータ取得\n",
    "cursor.execute('SELECT name, detail_url, onsen_info FROM hotels')\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# CSVに書き込み\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # ヘッダー\n",
    "    writer.writerow(['Hotel Name', 'Detail URL', 'Onsen Info'])\n",
    "    # データ\n",
    "    writer.writerows(rows)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(f\"スクレイピングしたホテル情報を '{db_name}' に保存し、'{csv_file}' に書き出しました。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
